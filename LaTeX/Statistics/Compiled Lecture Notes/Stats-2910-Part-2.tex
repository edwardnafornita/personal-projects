\documentclass[12pt, letterpaper]{article}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{mdframed}
\usepackage{amsmath}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\newcommand{\lecture} {
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
        \vbox{
            \vspace{2mm}
            \hbox to 6.28in {{\bf STAT 2910: Statistics for the Sciences \hfill InterSummer 2022}}
            \vspace{4mm}
            \hbox to 6.28in {{\Large \hfill Lecture Notes 2 \hfill}}
            \vspace{2mm}
            \hbox to 6.28in {\textbf{Name:} Edward Nafornita \hfill 
            \textbf{Professor:} Sudhir Paul
            }
            %% \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
            \vspace{2mm}
        }
    }
   \end{center}
   \markboth{STAT 2910: Lecture Notes}{STAT 2910: Lecture Notes}
   \vspace*{4mm}
}

\begin{document}
    \lecture
    \tableofcontents
    \newpage

    \section{Normal Probability Distribution}
        \subsection{Continuous Random Variables}
            \begin{itemize}
            \item Continuous Random Variables: can assume the infinitely many values corresponding to points on a line interval.
                \begin{itemize}
                    \item Examples: Heights, weights, length of life of a particular product, experimental laboratory error.
                \end{itemize}
            \item A smooth curve describes the probability distribution of a continuous random variable.
            \item The depth or density of the probability, which varies with $x$, may be descirbed by a mathematical formula $f(x)$, called the \textbf{probability distribution} or \textbf{probability density function} for the random variable $x$.
            \end{itemize}

        \subsection{Properties of Continuous Probability Distribution}
            \begin{description}
                \item[1] The area  under the curve is equal to 1.
                \item[2] $P(a \leq x \leq b)$ = \textbf{area under the curve} between $a$ and $b$.
                \item[3] There is no probability attached to any single value of $x$. That is, $P(x = a) = 0$.
            \end{description}
        \subsection*{Continuous Proabability Distributions}
            \begin{itemize}
                \item There are many different types of continuous random variables.
                \item We try to pick a model that
                    \begin{itemize}
                        \item Fits the data well
                        \item Allows us to make the best possible inferences using the data.
                    \end{itemize}
                \item One important continuous random variable is the \textbf{normal random variable}.
            \end{itemize}

        \subsection{Normal Distribution}
            \begin{itemize}
                \item The formula that generates the normal probability distribution is:
                \begin{equation}
                    f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
                \end{equation}
                    \begin{itemize}
                        \item For $-\infty < x < \infty$
                        \item $\mu$ and $\sigma$ are the population mean and standard deviation.
                    \end{itemize}
                \item The shape and location of the normal curve changes as the mean and standard deviation change.
            \end{itemize}

        \subsection{Standard Normal Distribution}
            \begin{itemize}
                \item To find $P(a < x < b)$, we need to find the area under the appropriate normal curve.
                \item To simplify the tabulation of these areas, we \textbf{standardize} each value of $x$ by expressing it as a $z$-score, the number of standard deviations $\sigma$ it lies from the mean $\mu$.
                    \begin{equation}
                        z = \frac{x-\mu}{\sigma}
                    \end{equation}
            \end{itemize}
            \subsection*{Properties of the Standard Normal Distribution}
            \begin{description}
                \item[1] Mean $= 0$; Standard Deviation $= 1$
                \item[2] When $x = \mu$, $z = 0$
                \item[3] Symmetric about $z = 0$
                \item[4] Values of $z$ to the left of center are neagtive
                \item[5] Values of $z$ to the right of center are positive
                \item[6] Total area under the curve is 1.
            \end{description}
            \subsubsection{Solve Problems Using Statistical Table 3}
                \begin{description}
                    \item[1] To find an area to the left of a $z$-value, find the area directly from the table.
                    \item[2] To find an area to the right of a $z$-value, find the area in Table 3 and subtract from 1.
                    \item[3] To find the area between two values of $z$, find the two areas in Table 3, and subtract one from the other.
                \end{description}
                \textbf{Recall:} Empirical Rule states that "approximately 95\% of the measurements lie within 2 standard deviations of the mean."
            
            \subsubsection{Finding Probabilities for the General Normal Random Variable}
                \begin{description}
                    \item[1] To find an area for a normal random variable $x$ with mean $\mu$ and standard deviation $\sigma$, standardize or rescale the interval in terms of $z$-values.
                    \item[2] Find the appropriate area using Table 3.
                \end{description}

        \subsection{Normal Approximation to the Binomial}
            \begin{itemize}
                \item We can calculate binomial probabilities using:
                \begin{itemize}
                    \item The binomial formula
                    \item The cumulative binomial tables
                \end{itemize}
                \item When $n$ is large, and $p$ is not too close to zero or one, areas under the normal curve with mean $np$ and variance $npq$ can be used to approximate binomial probabilities.
            \end{itemize}
            \subsubsection{Approximating the Binomial}
                \begin{itemize}
                    \item Make sure to include the entire rectangle for the values of $x$ in the interval of interest. This is called the \textbf{continuity correction}.
                    \item Standardize the values of $x$ using:
                    \begin{equation}
                        z = \frac{x - np}{\sqrt{npq}}
                    \end{equation}
                    \item Make sure that \underline{$np$ and $nq$ are both greater than 5} to avoid inaccurate approximations.
                \end{itemize}
    \section{Sampling Distributions} 
        \begin{itemize}
            \item Parameters are numerical descriptive measures for populations. The values of the parameters are generally unknown.
            \begin{itemize}
                \item Examples 1: Suppose height of the students of U. of W. is normally distributed with $\mu$ and $\sigma$.
                \begin{itemize}
                    \item The quantities $\mu$ and $\sigma$ are parameters. These are fixed but unknown.
                \end{itemize}
                \item Example 2: Suppose a proportion $p$ of people in Windsor have heart disease. Suppose you take a sample of $n$ people from Windsor. Let $x = $ number of people in the sample who have heart disease. Then, $x$ has a binomial distribution with index $n$ probability $p$.
                \begin{itemize}
                    \item The quantity $p$ is the parameter which is fixed but unknown.
                \end{itemize}
            \end{itemize}
        \end{itemize}
        \subsection{Sampling}
            Since it is time consuming and expensive to take all values of the population to obtain values of the population quantities such as $\mu$, $\sigma$ and $p$ we can take a sample to estimate these quantities.
            \begin{itemize}
                \item Example: Suppose that the mean height of the students of U. of W. is \\$\mu = 5.6$ft. Now suppose that you take 10 students from a sample of 25 \\students and obtained their values is as follows; \\$\bar{x}: 5.2, 5.7, 5.4, 5.8, 5.6, 5.9, 5.1, 5.6, 5.55, 5.67$.
                \item This example shows that the sample mean is not fixed. It is known as a random variable and it depends on which 25 students are in the sample.
                \item Since $\bar{x}$ is a random variable, it has a probability distribution.
                \item The quantities $\bar{x}$ and $s$ calculated from the sample to estimate the population quantities $\mu$ and $\sigma$ are called statistics. Thus the sample mean $\bar{x}$ is a statistic obtained from the sample to estimate the population mean $\mu$
            \end{itemize}
            \underline{Sample Variance:} $s^2$ is a statistic obtained from the sample to estimate the population variance $\sigma^2$.
            \\ \underline{Sample Proportion:} $\hat{p}$ is a statistic obtained from the sample to estimate the population proportion $p$.
            \\ Statistics vary from samle to sample and hence are random variables. The probability distributions for statistics are called \textbf{sampling distributions}. In repeated sampling, they tell us what values of the statistics can occur and how often each value occurs.
        
            \subsubsection{Sampling Distributions for Statistics} 
                \begin{description}
                    \item[1] Approximated with simulation techniques
                    \item[2] Derived using mathematical theorems
                    \begin{itemize}
                        \item Example: The Central Limit Theorem is one such example.
                    \end{itemize}
                \end{description}
                \begin{mdframed}[leftmargin=10pt, rightmargin=10pt]
                    \textbf{Central Limit Theorem:} If random samples of $n$ observations are drawn from a non-normal population with finite $\mu$ and standard deviation $\sigma$, then, when $n$ is large, the sampling distribution of the sample mean $\bar{x}$ is approximately normally distributed, with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$. The approximation becomes more accurate as $n$ becomes large.
                \end{mdframed}
            \subsubsection{Importance of Sampling Distributions for Statistics}
                \begin{itemize}
                    \item The \textbf{Central Limit Theorem} also implies that the sum of $n$ measurements is approximately normal with mean $n\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$
                    \item Man statistics that are used for statistical inference are \textbf{sums} or \textbf{averages} of sample measurements.
                    \item When $n$ is large, these statistics will have approximately \textbf{normal} distributions.
                \end{itemize}
            \subsubsection{Definition of Large}
            \begin{itemize}
                \item If the sample is from a \textbf{normal population}, then the sampling distribution of $\bar{x}$ will also be normal, no matter the sample size.
                \item When the sample population is approximately \textbf{symmetric}, the distribution becomes approximately normal for relatively small values of $n$.
                \item When the sample population is \textbf{skewed}, the sample size must be \textbf{at least 30} before the sampling distribution of $\bar{x}$ becomes approximately normal.
            \end{itemize}
        \subsection{Sampling Distribution of the Sample Mean}
            \begin{mdframed}[leftmargin=10pt, rightmargin=10pt]
            \begin{itemize}
                \item A random sample of size $n$ is selected from a population with mean $\mu$ and standard deviation $\sigma$.
                \item The sampling distribution of the sample mean $\bar{x}$ will have mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$.
                \item If the original population is \textbf{normal}, the sampling distribution will be normal for any sample size.
                \item If the original population is \textbf{non-normal}, the sampling distribution will be normal when $n$ is large. 
            \end{itemize}
            \end{mdframed}
            Note: Standard deviation of $\bar{x}$ is sometimes called the \underline{Standard Error (SE)}.
            \subsubsection{Finding Probabilities for the Sample Mean}
                \begin{itemize}
                    \item If the sampling distribution of $\bar{x}$ is normal or approximately normal, standardize or rescale the interval of interest in terms of $$z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}$$
                    \item Find the appropriate area using Table 3.
                \end{itemize}
                Example: A random sample of size $n = 16$ from a normal distribution with $\mu = 10$ and $\sigma = 8$. Then $P(\bar{x} > 12) = P(z > \frac{12-10}{\frac{8}{\sqrt{16}}}) = P(z > 1) = 1 - 0.8413 = 0.1587$.
                \newpage\subsubsection*{Example 2}
                    A soda filling machine is supposed to fill cans of soda with $12$ fluid ounces. Suppose that the fills are actually normally distributed with a mean of $12.1$ oz and a standard deviation of $0.2$ oz. What is the probability that the average fill for a six-pack of soda is less than $12$ oz?
                    \begin{align*}
                        P(\bar{x} < 12) = P\bigg(\frac{\bar{x}-\mu}{\frac{\sigma}{\sqrt{n}}} < \frac{12 - 12.1}{\frac{0.2}{\sqrt{6}}}\bigg) = P(z < 1.22) = 0.1112
                    \end{align*}
                    Therefore, the probability that the average fill for a six-pack of soda is less than $12$ oz is $0.1112$ or $11.12\%$.
        \subsection{Sampling Distribution of the Sample Proportion}
            \begin{itemize}
                \item The Central Limit Theorem can be used to conclude that the binomial random variable $x$ is approximately normal when $n$ is large, with mean $np$ and standard deviation.
                \item The sample proportion, $\hat{p} = \frac{x}{n}$ is simply a rescaling of the binomial random variable $x$, dividing it by $n$.
                \item From the Central Limit Theorem, the sampling distribution of $\hat{p}$ will also be approximately normal, with a rescaled mean and standard deviation.
            \end{itemize}
            \begin{mdframed}[leftmargin=10pt, rightmargin=10pt]
                \begin{itemize}
                    \item A random sample of size $n$ is selected from a binomial population with parameter $p$.
                    \item The sampling distribution of the sample proportion $\hat{p} = \frac{x}{n}$
                    \item It will have mean $p$ and standard deviation of $\sqrt{\frac{pq}{n}}$
                    \item If $n$ is large, and $p$ is not too close to 0 or 1, the sampling distribution will be approximately normal.
                    \item \underline{Note:} The standard deviation of $\hat{p}$ is sometimes called the \underline{Standard Error (SE)} of p-hat.
                \end{itemize}
            \end{mdframed}
            \subsubsection{Finding Probabilities for the Sample Proportion}
                If the sampling distribution of $\hat{p}$ is normal or approximately normal, standardize or rescale the interval of interest in terms of $$z = \frac{\hat{p} - p}{\sqrt{\frac{pq}{n}}}$$
                Then find the appropriate area using Table 3.
                \textbf{Example}
                    A random sample of size $n = 100$ from a binomial population with $p = 0.4$
                    \begin{align*}
                        P(\hat{p} > 0.5) = P\left(z > \frac{0.5 - 0.4}{\sqrt{\frac{0.4(0.6)}{100}}}\right) = P(z > 2.04) = 1 - 0.9793 = 0.0207
                    \end{align*}
                    The soda bottler in the previous example claims that only $5\%$ of the soda cans are underfilled. A quality control technician randomly samples $200$ cans of soda. What is the probability that more than $10\%$ of the cans are underfilled? 
                    \begin{align*}
                        n = 200
                        \\ S: \textnormal{underfilled can}
                        \\ p = P(S) = 0.05
                        \\ q = 0.95
                        \\ np = 10 
                        \\ nq = 190 
                    \end{align*}
                    \begin{align*}
                        P(\hat{p} > 0.5) = P\left(z > \frac{0.10 - 0.05}{\sqrt{\frac{0.05(0.95)}{100}}}\right) = P(z > 3.24) = 1 - 0.9994 = 0.0006
                    \end{align*}
                    Notice the very unusual probability, meaning that if $p = 0.05$ the probability would be unrealistic.
    \section{Large-Sample Estimation}
        \begin{itemize}
            \item Populations are described by their probability distributions and parameters.
            \begin{itemize}
                \item For quantitative populations, the location and shape are described by $\mu$ and $\sigma$.
                \item For a binomial populations, the location and shape are determined by $p$.
            \end{itemize}
            \item If the values of parameters are unknown, we make inferences about them using sample information.
        \end{itemize}
        \subsection*{Types of Inference}
            \begin{itemize}
                \item A consumer wants to estimate the average price of similar homes in her city before putting her home on the market. (\textbf{Estimation:} Estimate $\mu$, the average home price).
                \item A manufacturer wants to know if a new type of steel is more resistant to high temperatures than an old type was. (\textbf{Hypothesis Test:} Is the new average resistance $\mu_N$ equal to the old average resistance, $\mu_O$)?
            \end{itemize}
            Since an estimator is calculated from sample values, it varies from sample to sample according to its \underline{sampling distribution}.
        \subsection*{Define}
            \begin{itemize}
                \item A single value calculated from the sample is called a point estimate.
                \item $\bar{x}$ is a point estimate of the population parameter $\mu$.
                \item $\hat{p} = \frac{x}{n}$ is the point estimate of the population parameter $p$.
                \item $s^2$ is the point estimate of $\sigma^2$.
            \end{itemize}
        \subsection{Interval Estimation}
            \begin{itemize}
                \item Create an interval $(a, b)$ so that you are fairly sure that the parameter lies between these two values.
                \item "Fairly sure" means "with high probability" measured using the \textbf{confidence coefficient}, $1 - \alpha$.
                \item Suppose $1 - \alpha = 0.95$ and that the estimator has a normal distribution. Since we don't know the value of the parameter, consider the Estimator $\pm 1.96$SE which has a variable center. Only if the estimator falls in the tail areas will the interval fail to enclose the parameter. This happens only $5\%$ of the time. 
            \end{itemize}
        \subsection*{Changing the Confidence Level}
            \begin{itemize}
                \item To change to a general confidence level, $1 - \alpha$, pick a value of $z$ that puts area $1 - \alpha$ in the center of the $z$-distribution. $$100(1 - \alpha) = \textnormal{Confidence Interval: Estimator} \pm z_{\frac{\alpha}{2}}\textnormal{SE}$$
            \end{itemize}
        \subsection*{Margin of Error}
            \begin{itemize}
                \item For estimators with normal sampling distributions, $95\%$ of all point estimates will lie within $1.96$ standard deviations of the parameter of interest.
                \item \textbf{Margin of Error:} the maximum error of estimation, calculated as $1.96$(standard error of the estimator).
            \end{itemize}
        \subsection{Estimating Means and Proportions}
            \begin{itemize}
                \item For a quantitative population, \\ Point Estimator of population mean $\mu : \bar{x}$ \\ Margin of Error $(n \geq 30): \pm 1.96\frac{s}{\sqrt{n}}$
                \item For a binomial population, \\ Point Estimator of population proportion $p : \hat{p} = \frac{x}{n}$ \\ Margin of Error $(n \geq 30) : \pm 1.96\sqrt{\frac{\hat{p}\hat{q}}{n}}$ 
            \end{itemize}
            \subsubsection*{Examples}
                \begin{itemize}
                    \item[1] A homeowner randomly samples 64 homes similar to her own and finds that the average selling price is \$250,000 with a standard deviation of \$15,000. Estimate the average selling price for all similar homes in the city.
                    \begin{mdframed}[leftmargin=0.5cm,rightmargin=0.5cm]
                        Point Estimator of $\mu : \bar{x} = 250,000$
                        \\ Margin of Error: $\pm 1.96\frac{s}{\sqrt{n}} = \pm 1.96\frac{15,000}{\sqrt{64}} = \pm 3675$
                    \end{mdframed} 
                    \item[2] A quality control technician wants to estimate the proportion of soda cans that are underfilled. He randomly samples 200 cans of soda and finds 10 underfilled cans.
                    \begin{mdframed}[leftmargin = 0.5cm, rightmargin = 0.5cm]
                        $n = 200 \hspace{3cm} p =$ proportion of underfilled cans \\ 
                        Point Estimator of $p : \hat{p} = \frac{x}{n} = \frac{10}{200} = 0.05$ \\
                        Margin of Error: $\pm 1.96\sqrt{\frac{\hat{p}\hat{q}}{n}} = \pm 1.96\sqrt{\frac{0.05(0.95)}{200}} = \pm 0.03$
                    \end{mdframed}
                \end{itemize}
        \subsection{Confidence Intervals for Means and Proportions}
            \begin{itemize}
                \item For a quantitative population, \\ Confidence interval for a population mean $\mu : \bar{x} \pm z_{\frac{\alpha}{2}}\frac{s}{\sqrt{n}}$
                \item For a binomial population, \\ Confidence interval for a population proportion $p  : \hat{p} \pm z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}\hat{q}}{n}}$
            \end{itemize}
            \subsubsection*{Examples}
                \begin{itemize}
                    \item[3] A random sample of $n = 50$ males showed a mean average daily intake of dairy products equal to 756 grams with a standard deviation of 35 grams. Find a 95\% confidence interval for the population average $\mu$.
                    \item[-] Note: The population mean of the daily intake of dairy products is $\mu$. A 95\% confidence interval for $\mu$: 
                    \begin{mdframed}[leftmargin=0.5cm,rightmargin=0.5cm]
                        $\bar{x} \pm 1.96\frac{s}{\sqrt{n}} \Rightarrow  756 \pm 1.96\frac{35}{\sqrt{50}} \Rightarrow 750\pm 9.70$ or $746.30 < \mu < 765.70$ grams.
                    \end{mdframed}
                \end{itemize}
            \subsubsection*{Interpretation of the Confidence Interval in Example 3}
                \begin{itemize}
                    \item[-] Intervals constructed in this manner will enclose the population mean $\mu$ 95\% times in repeated sampling.
                    \item[-] Note: Interpretation is the same for confidence interval of any parameter we construct.
                \end{itemize}
                \begin{itemize}
                    \item[4] Find a 99\% confidence interval for $\mu$, the population average daily intake of dairy products for men.
                    \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                        $\bar{x} \pm 2.58 \frac{s}{\sqrt{n}} \Rightarrow 756 \pm 2.58 \frac{35}{\sqrt{50}} \Rightarrow 756\pm 12.77$ or $743.23 < \mu < 768.77$ grams.
                        Note: The interval must be wider to provide for the increased confidence that is does indeed enclose the true value of $\mu$.
                    \end{mdframed}
                    \item[-] Intervals constructed in this manner will enclose the population mean 99\% times in repeated sampling.
                    \item[5] Of a random sample of $n = 150$ college students, 104 of the students said that they had played on a soccer team during their K-12 years. Estimate the proportions of college students who played soccer in their youth with a 98\% confidence interval.
                    \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                        $\hat{p} \pm 2.33\sqrt{\frac{\hat{p}\hat{q}}{n}} \Rightarrow \frac{104}{150} \pm 2.33 \sqrt{\frac{0.69(0.31)}{150}} \Rightarrow 0.69\pm 0.09$ or $0.60 < p < 0.78$
                    \end{mdframed}
                    \item[-] Intervals constructed in this manner will enclose the population proportion 98\% times in repeated sampling.
                \end{itemize}
        \subsection{Estimating the Difference between Two Means}
            \begin{itemize}
                \item Sometimes we are interested in comparing the means of two populations.
                \begin{itemize}
                    \item The average growth of plants fed using two different nutrients.
                    \item The average scores for students taught with two different teaching methods.
                \end{itemize}
                \item We compare the two averages by making inferences about $\mu_1 - \mu_2$, the difference in the two population averages.
                \begin{itemize}
                    \item If the two population averages are the same, then $\mu_1 - \mu_2 = 0$.
                    \item The best estimate of $\mu_1 - \mu_2$ is the difference between the sample means, $\bar{x}_1 - \bar{x}_2$.
                \end{itemize}
            \end{itemize}
        \subsection{Sampling Distribution of the Sample Means}
            \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                \begin{itemize}
                    \item[1] The mean of $\bar{x}_1 - \bar{x}_2$ is $\mu_1 - \mu_2$, the difference in the population means.
                    \item[2] The standard deviation of $\bar{x}_1 - \bar{x}_2$ is SE $= \sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}}$.
                    \item[3] If the sample sizes are large, the sampling distribution of $\bar{x}_1 - \bar{x}_2$ is approximately normal, and SE can be estimated as SE $= \sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}}$.
                \end{itemize}
            \end{mdframed}
            \subsubsection{Estimating Population Means}
                \begin{itemize}
                    \item For large samples, point estimates and their margin of error as well as confidence intervals are based on the standard normal $(z)$ distribution.
                    \item[-] Point Estimate for $\mu_1-\mu_2 : \bar{x}_1-\bar{x}_2$ \\ Margin of Error : $\pm 1.96\sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}}$ \\ Confidence Interval for $\mu_1-\mu_2 : (\bar{x}_1-\bar{x}_2\pm z_{\frac{\alpha}{2}}\sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}})$
                \end{itemize}
            \subsubsection*{Example}
                \begin{tabular}{|l|l|l|}
                    \cline{1-3}
                    \textbf{Average Daily Intakes} & Men & Women \\ \cline{1-3}
                    Sample Size & 50 & 50 \\ \cline{1-3}
                    Sample Mean & 756 & 762 \\ \cline{1-3}
                    Standard Deviation & 35 & 30 \\ \cline{1-3}
                \end{tabular}
                \begin{itemize}
                    \item Compare the average daily intake of dairy products of men and women using a 95\% confidence interval.
                \end{itemize}
                \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                    \begin{align*}
                        (\bar{x}_1 - \bar{x}_2\pm 1.96\sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}} \Rightarrow (756 - 762)\pm 1.96\sqrt{\frac{35^2}{\sqrt{50}} + \frac{30^2}{\sqrt{50}}} \\ \Rightarrow -6\pm 12.78 \hspace{3pt} \textnormal{or} -18.78 < \mu_1 - \mu_2 < 6.78)
                    \end{align*}
                \end{mdframed}
                \subsubsection*{Notice}
                \begin{itemize}
                    \item Could you conclude, based on this confidence interval, that there is a difference in the average daily intake of dairy products for men and women?
                    \item[-] The confidence interval contains the value $\mu_1 - \mu_2 = 0$. Therefore, it is possible that $\mu_1 = \mu_2$. You would not want to conclude that there is a difference in average daily intake of dairy products for men and women. 
                \end{itemize}
            \subsubsection{Estimating the Difference between Two Proportions}
                \begin{itemize}
                    \item Sometimes we are interested in comparing the proportion of \underline{successes} in two binomial populations.
                    \begin{itemize}
                        \item[-] The germination rates of untreated seeds and seeds treated with a fungicide.
                        \item[-] The proportion of male and female voters who favour a particular candidate for governor.
                    \end{itemize}
                    \item A random sample of size $n_1$ drawnfrom binomial population with parameter $p_1$ and a random sample size of $n_2$ drawn from binomial population with parameter $p_2$.
                    \item We compare teh two proportions by making inferences about $p_1 - p_2$, the difference in the two population proportions.
                    \item[-] If the two population proportions are the same, then $p_1 - p_2 = 0$.
                    \item[-] The best estimate of $p_1 - p_2$ is the difference between the sample proportions, $$\hat{p}_1 - \hat{p}_2 = \frac{x_1}{n_1} - \frac{x_2}{n_2}$$
                \end{itemize}
        \subsection{Sampling Distribution of Sample Proportions}
            \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                \begin{itemize}
                    \item[1] The mean of $\hat{p}_1 - \hat{p}_2$ is $p_1 - p_2$, the difference in the population proportions.
                    \item[2] The standard deviation of $\hat{p}_1 - \hat{p}_2$ is SE $= \sqrt{\frac{p_1q_1}{n_1} + \frac{p_2q_2}{n_2}}$.
                    \item[3] If the sample sizes are large, the sampling distribution of $\hat{p}_1 - \hat{p}_2$ is approximately normal, and SE can be estimated as SE $= \sqrt{\frac{\hat{p}_1\hat{q}_1}{n_1} + \frac{\hat{p}_2\hat{q}_2}{n_2}}$.
                \end{itemize}
            \end{mdframed}
            \subsubsection{Estimating Population Proportions}
                \begin{itemize}
                    \item For large samples, point estimates and their margin of error as well as confidence intervals are based on the standard normal $(z)$ distribution.
                    \item[-] Point Estimate for $p_1-p_2 : \hat{p}_1-\hat{p}_2$ \\ Margin of Error : $\pm 1.96\sqrt{\frac{\hat{p}_1\hat{q}_1}{n_1} + \frac{\hat{p}_2\hat{q}_2}{n_2}}$ \\ Confidence Interval for $p_1-p_2 : (\hat{p}_1-\hat{p}_2\pm z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}_1\hat{q}_1}{n_1} + \frac{\hat{p}_2\hat{q}_2}{n_2}})$
                \end{itemize}
            \newpage\subsubsection*{Example}
                \begin{tabular}{|l|l|l|}
                    \cline{1-3}
                    \textbf{Youth Soccer} & Male & Female \\ \cline{1-3}
                    Sample Size & 80 & 70 \\ \cline{1-3}
                    Played Soccer & 65 & 39 \\ \cline{1-3}
                \end{tabular}
                \begin{itemize}
                    \item Compare the proportions of male and female college students who said that they had played on a soccer team during their K-12 years using a 99\% confidence interval.
                \end{itemize}
                \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                    \begin{align*}
                        (\hat{p}_1 - \hat{p}_2)\pm 2.58\sqrt{\frac{\hat{p}_1\hat{q}_1}{n_1} + \frac{\hat{p}_2\hat{q}_2}{n_2}} \Rightarrow \left(\frac{65}{80} - \frac{39}{70} \right) \pm 2.58\sqrt{\frac{0.89(0.19)}{80} + \frac{0.56(0.44)}{70}} \\ \Rightarrow 0.25\pm 0.19 \hspace{3pt} \textnormal{or} \hspace{3pt} 0.06 < p_1 - p_2 < 0.44                    
                    \end{align*}
                \end{mdframed}
                \subsubsection*{Notice}
                    \begin{itemize}
                        \item Could you conclude, based on this confidence interval, that there is a difference in the proportion of male and female college students who said that they had played on a soccer team during their K-12 years?
                        \item The confidence interval does not contain the value $p_1 - p_2 = 0$. Therefore, it is not likely that $p_1 = p_2$. You would conclude that there is a difference in the proportions for males and femals.
                        \item[IE:] "A higher proportion of males than females played soccer in their youth."
                    \end{itemize}
            \subsubsection{Choosing the Sample Size}
                \begin{itemize}
                    \item The total amount of relevant information in a sample is controlled by two factors: 
                    \begin{itemize}
                        \item The \textbf{sampling plan} or \textbf{experimental design:} the procedure for collecting the information.
                        \item The \textbf{sample size $n$:} the amount of information you collect.
                    \end{itemize}
                    \item In a statistical estimation problem, the accuracy of the estimation is measured by the margin of error or the "width of the confidence interval".
                    \item To Choose the Sample Size: 
                    \begin{itemize}
                        \item[1] Determine the size of the margin of error, $B$, that you are willing to tolerate.
                        \item[2] Choose the sample size by solving for $n$ or $n = n_1 = n_2$ in the inequality: 1.96 SE $= B$, where SE is a function of the sample size $n$.
                        \item[3] For quantitative populations, estimate the population standard deviation using a previously calculated value of $s$ or the range approximation $\sigma \approx \frac{\textnormal{Range}}{4}$.
                        \item[4] For binomial populations, use the conservative approach and approximate $p$ using the value $p = 0.5$. 
                    \end{itemize}
                \end{itemize}
            \subsubsection*{Example}
                \begin{itemize}
                    \item[-] A producer of PVC pipe wants to survey wholesalers who buy his product in order to estimate the proportion who plan to increase their purchases next year. What sample size is required if he wants his estimate to be within 0.04 of the actual proportion with probability equal to 0.95?
                \end{itemize}
                \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                    \begin{align*}
                        1.96\sqrt{\frac{pq}{n}} = 0.04 \Rightarrow 1.96\sqrt{\frac{0.5(0.5)}{n}} = 0.04 \Rightarrow \sqrt{n} = \frac{1.96\sqrt{0.5(0.5)}}{0.04} = 24.5 \\ \Rightarrow n = 24.5^2 = 600.25
                    \end{align*}
                \end{mdframed}
    \section{Large-Sample Tests of Hypotheses}
        \subsection{Hypothesis, Null and Alternative Hypothesis}
            \begin{itemize}
                \item Any statement regarding the value of a population parameter is called a hypothesis.
                \item The hypothesis to be tested is called null hypothesis.
                \item The complement of the null hypothesis is called an alternative hypothesis.
            \end{itemize}
            \subsubsection{One and Two Sided Alternatives}
                \begin{itemize}
                    \item The null hypothesis is always a single value of the parameter, $H_0 : \mu = \mu_0$
                    \item The alternative hypothesis can be two sided, $H_A : \mu \neq \mu_0$ or one sided, $H_A : \mu < \mu_0$ or $H_A : \mu > \mu_0$.
                \end{itemize}
            \subsubsection*{Example}
                \begin{itemize}
                    \item[1] A drug manufacturer claimed that the mean potency, $\mu$, of one of its antibiotics was 80\%. A random sample of $n = 100$ capsules were tested and produced a sample mean of $\bar{x} = 79.7\%$, with a standard deviation of $s = 0.8\%$. Does the data present sufficient evidence to refute the manufactuerer's claim?
                    \item[-] Here $H_0 : \mu = 80$ is the null hypothesis and $H_A : \mu \neq 80\%$ is the alternative hypothesis. \underline{Note:} the alternative is two sided.
                    \item[2] A drug manufactuerer claimed that the mean potency, $\mu$, of one of its antibiotics was less than 80\%. A random sample of $n = 100$ capsules were tested and produced a sample mean of $\bar{x} = 79.7\%$, with a standard deviation of $s = 0.8\%$. Does the data present sufficient evidence to refute the manufactuerer's claim?
                    \item[-] Here $H_0 : \mu = 80$ is the null hypothesis and $H_A : \mu < 80$ is the alternative hypothesis. \underline{Note:} the alternative is one sided. 
                \end{itemize}
        \subsection{Testing a Null Hypothesis}
            \begin{itemize}
                \item We need a quantity which is called a test statistic.
                \item We can then test using one of the three methods:
                \item[1] Critical value of the test statistic.
                \item[2] Using a P-value. 
                \item[3] Confidence Interval Method.
            \end{itemize}
            \subsubsection{Critical Value Method}
                \begin{itemize}
                    \item Consider a two sided alternative hypothesis. Notes that the null hypothesis always specifies a single value of the parameter. $H_0 : \mu = \mu_0$, $H_A : \mu \neq \mu_0$.
                    \item \underline{Note:} The Rejection Region - Reject $H_0$ if $z > 2.33$, if the test statistic falls in the rejection region, its p-value will be less than $\alpha = 0.01$.
                    \begin{itemize}
                        \item Additionally, reject $H_0$ if $z < -1.645$ if the test statistic falls in the rejection region, its p-value will be less than $\alpha = 0.05$.
                    \end{itemize}
                \end{itemize}
            \subsubsection*{Test Statistic}
                \begin{itemize}
                    \item Assume to begin with that $H_0$ is true. The sample mean $\bar{x}$ is our best estimate of $\mu$, and we use it in a standardized form as the \textbf{test statistic:}
                    \begin{equation*}
                        z = \frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \approx \frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}}
                    \end{equation*}
                    \item[-] Since $\bar{x}$ has an approximate normal distribution with mean $\mu_0$ and standard deviation $\frac{\sigma}{\sqrt{n}}$, the test statistic is approximately normal.
                    \item If $H_0$ is true the value of $\bar{x}$ should be close to $\mu_0$, and $z$ will be close to zero. If $H_0$ is false, $\bar{x}$ will be much larger or smaller than $\mu_0$, and $z$ will be much larger or smaller than zero, indicating that we should reject $H_0$.
                \end{itemize}
            \subsubsection*{Large Sample Test of a Population Mean}
                \begin{itemize}
                    \item Take a random sample of size $n \geq 30$ from a population with mean $\mu$ and standard deviation $\sigma$.
                    \item We assume that either: $\sigma$ is known or $s \approx \sigma$ since $n$ is large.
                \end{itemize}
            \subsubsection*{Parts of a Statistical Test}
                \textbf{Conclusion:}
                    \begin{itemize}
                        \item[-] Either "Reject $H_0$" or "Do not reject $"H_0$", along with a statement about the reliability of your conclusion.
                    \end{itemize}
                \textbf{How do you decide when to reject $H_0$?}
                    \begin{itemize}
                        \item[-] Depends on the \textbf{significance level ($\alpha$)}, the maximum tolerable risk you want to have of making a mistake, if you decide to reject $H_0$.
                        \item[-] Usually, the significance level is $\alpha = 0.01$ or $\alpha = 0.05$.
                    \end{itemize}
                From Example [1], the value of the test statistic is,
                \begin{equation*}
                    Z = \frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}} = \frac{79.7-80}{\frac{0.8}{\sqrt{100}}} = -3.75
                \end{equation*}
            \subsubsection*{Example 1 Revisited}
                \begin{itemize}
                    \item Critical Value Method:
                    \begin{itemize}
                        \item[-] Take $\alpha = 0.05$, then $Z_{\frac{\alpha}{2}} = Z_{0.025} = 1.96$.
                        \item[-] Since $|Z| = 3.75 > Z_{0.025} = 1.96$, we reject the null hypothesis ($H_0$) at 5\% level of significance. Therefore, there is insufficient evidence in the data to support the manufacturer's claim.
                    \end{itemize}
                \end{itemize}
            \subsubsection{P-Value Method: Likely or Unlikely?}
                \begin{itemize}
                    \item Once you've calculated the observed value of the test statistic, calculate its \textbf{p-value} using the following formula:
                \end{itemize}
                \newpage\begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                    \textbf{p-value:} The probability of observing, just by chance, a test statistic as extreme or even more extreme than what we've actually observed. If $H_0$ is rejected this is the actual probability that we have made an incorrect decision.
                \end{mdframed}
                \begin{itemize}
                    \item If this probability is very small, less than some preassigned significance level ($\alpha$), then we can reject $H_0$.
                    \item If the alternative hypothesis is one-sided, $H_A : \mu < \mu_0$, then the $p-\textnormal{value} = p(Z < -Z_0)$ and $Z_0 = \left|\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}}\right|$. \underline{Note:} Reverse both equality symbols if the null hypothesis had a inverted equality than the example.
                    \item However if $H_A : \mu \neq \mu_0$, then the $p-\textnormal{value} = 2p(Z < -Z_0)$ and $Z_0 = \left|\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}}\right|$.
                \end{itemize}
            \subsubsection*{Example 1 Revisited}
                \begin{itemize}
                    \item The null and alternative hypothesises are: $H_0 : \mu = 80$ and $H_A : \mu \neq 80$.
                    \item Z = -3.75
                    \item P-value for this test is: $p-\textnormal{value} = 2p(Z < -3.75) = 0.0$
                    \item[-] Since $p-\textnormal{value} < 0.05$, we reject the null hypothesis at 5\% level of significance.
                \end{itemize}
            \subsubsection{Statistical Significance of P-Values}
                \begin{itemize}
                    \item If the $p-\textnormal{value}$ is less than 0.01, reject $H_0$. The results are \textbf{highly significant}.
                    \item If the $p-\textnormal{value}$ is between 0.01 and 0.05, reject $H_0$. The results are \textbf{statistically significant}.
                    \item If the $p-\textnormal{value}$ is between 0.05 and 0.10, do not reject $H_0$. The results are \textbf{tending towards significance}.
                    \item If the $p-\textnormal{value}$ is greater than 0.10, do not reject $H_0$. The results are \textbf{not statistically significant}.
                \end{itemize}
        \subsection{Confidence Interval Method}
            \begin{itemize}
                \item Confidence interval method can only be applied to a two-sided test.
                \item Construct a $(1-\alpha)100\%$ confidence interval. Then, if the value of the parameter under teh nul hypothesis falls in this interval then we do not reject the null hypothesis. Otherwise we reject the null hypothesis in favor of the alternative.
            \end{itemize}
            \subsubsection*{Example}
                \begin{itemize}
                    \item A homeowner randomly samples 64 homes similar to her own and finds that the average selling price is \$252,000 with a standard deviation of \$15,000. Is there sufficient evidence to conclude that the average selling price in her area is \$250,000? Use $\alpha = 0.01$.
                    \item So: $H_0 : \mu = 250,000$ is the null hypothesis. $H_A : \mu \neq 250,000$ is the alternative hypothesis. \underline{Note:} the alternative is two-sided.
                    \item Additionally: A 99\% confidence interval for population mean is: 
                    \begin{align*}
                        \left(\bar{x}-z_{\frac{\alpha}{2}}\frac{s}{\sqrt{n}}, \bar{x}+z_{\frac{\alpha}{2}}\frac{s}{\sqrt{n}}\right) = \left(252000 - 2.575\frac{15000}{\sqrt{64}}, 252000+2.575\frac{15000}{\sqrt{64}}\right) \\
                        \Rightarrow (247171.90, 256828.10)
                    \end{align*}
                    \item[-] Since 250,000 is included in the 99\% confidence interval we do not reject the null hypothesis. There is evidence in the data to suggest that the mean selling price is \$250,000.
                \end{itemize}
            \subsubsection{Statistical Significance of the Confidence Interval Method}
                \begin{itemize}
                    \item The critical value approach and the $p-\textnormal{value}$ approach produce identical results.
                    \item The $p-\textnormal{value}$ approach is often preferred because:
                    \begin{itemize}
                        \item Computer printouts usually calculate $p-\textnormal{value}$
                        \item You can evaluate the test results at any significance level you choose.
                    \end{itemize}
                    \item[Q:] What should you do if you are the experimenter and no one gives you a significance level to use?
                    \item The General Test Statistic: $$z = \frac{\textnormal{statistic} - \textnormal{hypothesized value}}{\textnormal{standard error of statistic}}$$
                \end{itemize}
        \subsection{Testing the Difference between Two Means}
            \begin{itemize}
                \item[-] A random sample of size $n_1$ is drawn from population 1 with mean $\mu_1$ and variance $\sigma_1^2$.
                \item[-] A random sample of size $n_2$ is drawn from population 2 with mean $\mu_2$ and variance $\sigma_2^2$.
                \item The hypothesis of interest involves the difference, $\mu_1 - \mu_2$, in the form: $H_0 : \mu_1 - \mu_2 = D_0$ versus $H_a : \textnormal{one of three}$ where $D_0$ is the hypothesized difference, usually zero.
            \end{itemize}
            \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                \begin{flushleft}
                        $H_0$ : $\mu_1 - \mu_2 = D_0$ \\
                        $H_a$ : one of three alternatives \\ 
                        Test Statistic: $z \approx \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$ \\
                        with rejection regions and/or $p$-values based on the standard normal $z$ distribution.
                \end{flushleft}
            \end{mdframed}
        \subsection{Testing a Binomial Proportion}
            \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                \begin{flushleft}
                    A random sample of size $n$ from a binomial population is selected to test. \\
                    $H_0$ : $p = p_0$ versus $H_a$ : one of three alternatives \\
                    Test Statistic: $z \approx {\frac{\hat{p}-p_0}{\sqrt{\frac{p_0q_0}{n}}}}$ \\
                    with rejection regions and/or $p$-values based on the standard normal $z$ distribution.
                \end{flushleft}
            \end{mdframed}
        \subsection{Testing the Difference between Two Proportions}
            \begin{mdframed}[leftmargin=0.5cm, rightmargin=0.5cm]
                \begin{flushleft}
                    $H_0$ : $p_1 - p_2 = 0$ versus $H_a$ : one of three alternatives \\ 
                    Test Statistic: $z \approx {\frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}\hat{q}\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}}$ \\
                    with $\hat{p} = \frac{x_1 + x_2}{n_1 + n_2}$ to estimate the common value of $p$ and rejection regions or $p$-values based on the standard normal $z$ distribution.
                \end{flushleft}
            \end{mdframed}
        \subsection{Steps in Hypothesis Testing}
            \begin{itemize}
                \item Set up the null and the alternative hypothesises.
                \item Calculate the test statistic.
                \item Obtain the critical value or the $p$-value or and appropriate confidence interval and make a decision as to reject or not to reject the null hypothesis.
                \item Make a decision and write a conclusion with reason.
            \end{itemize}
\end{document}